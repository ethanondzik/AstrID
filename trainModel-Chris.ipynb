{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51c6a31-0548-4f9f-b1ca-2652f2caadde",
   "metadata": {},
   "source": [
    "# **AstrID:**  *model training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8c9b41-da1a-431e-8133-f228618ec132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 00:55:57.278562: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-18 00:55:58.572036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.preprocessing import image\n",
    "from keras.initializers import he_uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Import custom function to create and train the U-Net model\n",
    "from models.unet import unet_model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "\n",
    "# Import custom functions to extract Image arrays and Pixel Mask arrays from our created fits files dataset\n",
    "from dataGathering import extractImageArray, extractPixelMaskArray, extract_star_catalog\n",
    "from dataGathering import getStarData, getImagePlot, getPixelMaskPlot\n",
    "from dataGathering import displayRawImage, displayRawPixelMask, displayImagePlot, displayPixelMaskPlot, displayPixelMaskOverlayPlot\n",
    "\n",
    "# Import custom functions to preprocess Image and Pixel Mask arrays\n",
    "from imageProcessing import normalizeImages, stackImages, stackMasks, preprocessImage\n",
    "\n",
    "# Import custom logging function\n",
    "from log import write_to_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d260a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 00:56:02.129427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 00:56:02.270407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 00:56:02.270514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8bde07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 00:56:02.298634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 00:56:02.298769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 00:56:02.298816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 00:56:02.539189: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 00:56:02.539489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 00:56:02.539512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-18 00:56:02.539706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-18 00:56:02.539765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6878 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(\"GPU is available\")\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    K.clear_session()\n",
    "    tf.config.experimental.reset_memory_stats('GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b75e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getStarData('II/246', 250, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ad1a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data47.fits added to dataset\n",
      "data8.fits added to dataset\n",
      "data93.fits added to dataset\n",
      "data202.fits added to dataset\n",
      "data79.fits added to dataset\n",
      "data116.fits added to dataset\n",
      "data187.fits added to dataset\n",
      "data100.fits added to dataset\n",
      "data10.fits added to dataset\n",
      "data91.fits added to dataset\n",
      "data34.fits added to dataset\n",
      "data117.fits added to dataset\n",
      "data148.fits added to dataset\n",
      "data107.fits added to dataset\n",
      "data38.fits added to dataset\n",
      "data134.fits added to dataset\n",
      "data238.fits added to dataset\n",
      "data136.fits added to dataset\n",
      "data5.fits added to dataset\n",
      "data189.fits added to dataset\n",
      "data33.fits added to dataset\n",
      "data223.fits added to dataset\n",
      "data162.fits added to dataset\n",
      "data13.fits added to dataset\n",
      "data28.fits added to dataset\n",
      "data208.fits added to dataset\n",
      "data118.fits added to dataset\n",
      "data197.fits added to dataset\n",
      "data143.fits added to dataset\n",
      "data178.fits added to dataset\n",
      "data102.fits added to dataset\n",
      "data200.fits added to dataset\n",
      "data129.fits added to dataset\n",
      "data174.fits added to dataset\n",
      "data211.fits added to dataset\n",
      "data239.fits added to dataset\n",
      "data210.fits added to dataset\n",
      "data175.fits added to dataset\n",
      "data11.fits added to dataset\n",
      "data59.fits added to dataset\n",
      "data138.fits added to dataset\n",
      "data112.fits added to dataset\n",
      "data226.fits added to dataset\n",
      "data170.fits added to dataset\n",
      "data42.fits added to dataset\n",
      "data180.fits added to dataset\n",
      "data214.fits added to dataset\n",
      "data236.fits added to dataset\n",
      "data26.fits added to dataset\n",
      "data145.fits added to dataset\n",
      "data206.fits added to dataset\n",
      "data179.fits added to dataset\n",
      "data201.fits added to dataset\n",
      "data40.fits added to dataset\n",
      "data161.fits added to dataset\n",
      "data157.fits added to dataset\n",
      "data246.fits added to dataset\n",
      "data217.fits added to dataset\n",
      "data82.fits added to dataset\n",
      "data141.fits added to dataset\n",
      "data151.fits added to dataset\n",
      "data71.fits added to dataset\n",
      "data231.fits added to dataset\n",
      "data125.fits added to dataset\n",
      "data204.fits added to dataset\n",
      "data126.fits added to dataset\n",
      "data92.fits added to dataset\n",
      "data57.fits added to dataset\n",
      "data58.fits added to dataset\n",
      "data212.fits added to dataset\n",
      "data27.fits added to dataset\n",
      "data21.fits added to dataset\n",
      "data137.fits added to dataset\n",
      "data19.fits added to dataset\n",
      "data90.fits added to dataset\n",
      "data213.fits added to dataset\n",
      "data183.fits added to dataset\n",
      "data142.fits added to dataset\n",
      "data46.fits added to dataset\n",
      "data132.fits added to dataset\n",
      "data88.fits added to dataset\n",
      "data98.fits added to dataset\n",
      "data154.fits added to dataset\n",
      "data173.fits added to dataset\n",
      "data63.fits added to dataset\n",
      "data182.fits added to dataset\n",
      "data123.fits added to dataset\n",
      "data133.fits added to dataset\n",
      "data144.fits added to dataset\n",
      "data171.fits added to dataset\n",
      "data23.fits added to dataset\n",
      "data245.fits added to dataset\n",
      "data96.fits added to dataset\n",
      "data244.fits added to dataset\n",
      "data232.fits added to dataset\n",
      "data37.fits added to dataset\n",
      "data228.fits added to dataset\n",
      "data16.fits added to dataset\n",
      "data61.fits added to dataset\n",
      "data215.fits added to dataset\n",
      "data106.fits added to dataset\n",
      "data17.fits added to dataset\n",
      "data227.fits added to dataset\n",
      "data105.fits added to dataset\n",
      "data56.fits added to dataset\n",
      "data185.fits added to dataset\n",
      "data188.fits added to dataset\n",
      "data108.fits added to dataset\n",
      "data24.fits added to dataset\n",
      "data124.fits added to dataset\n",
      "data222.fits added to dataset\n",
      "data186.fits added to dataset\n",
      "data158.fits added to dataset\n",
      "data66.fits added to dataset\n",
      "data12.fits added to dataset\n",
      "data121.fits added to dataset\n",
      "data76.fits added to dataset\n",
      "data68.fits added to dataset\n",
      "data240.fits added to dataset\n",
      "data165.fits added to dataset\n",
      "data190.fits added to dataset\n",
      "data198.fits added to dataset\n",
      "data103.fits added to dataset\n",
      "data184.fits added to dataset\n",
      "data219.fits added to dataset\n",
      "data52.fits added to dataset\n",
      "data99.fits added to dataset\n",
      "data43.fits added to dataset\n",
      "data51.fits added to dataset\n",
      "data84.fits added to dataset\n",
      "data249.fits added to dataset\n",
      "data70.fits added to dataset\n",
      "data7.fits added to dataset\n",
      "data97.fits added to dataset\n",
      "data45.fits added to dataset\n",
      "data35.fits added to dataset\n",
      "data3.fits added to dataset\n",
      "data36.fits added to dataset\n",
      "data160.fits added to dataset\n",
      "data159.fits added to dataset\n",
      "data176.fits added to dataset\n",
      "data6.fits added to dataset\n",
      "data14.fits added to dataset\n",
      "data25.fits added to dataset\n",
      "data65.fits added to dataset\n",
      "data20.fits added to dataset\n",
      "data1.fits added to dataset\n",
      "data209.fits added to dataset\n",
      "data104.fits added to dataset\n",
      "data114.fits added to dataset\n",
      "data30.fits added to dataset\n",
      "data229.fits added to dataset\n",
      "data230.fits added to dataset\n",
      "data130.fits added to dataset\n",
      "data205.fits added to dataset\n",
      "data111.fits added to dataset\n",
      "data193.fits added to dataset\n",
      "data146.fits added to dataset\n",
      "data41.fits added to dataset\n",
      "data15.fits added to dataset\n",
      "data31.fits added to dataset\n",
      "data83.fits added to dataset\n",
      "data89.fits added to dataset\n",
      "data109.fits added to dataset\n",
      "data135.fits added to dataset\n",
      "data164.fits added to dataset\n",
      "data199.fits added to dataset\n",
      "data115.fits added to dataset\n",
      "data218.fits added to dataset\n",
      "data49.fits added to dataset\n",
      "data18.fits added to dataset\n",
      "data131.fits added to dataset\n",
      "data203.fits added to dataset\n",
      "data149.fits added to dataset\n",
      "data120.fits added to dataset\n",
      "data67.fits added to dataset\n",
      "data224.fits added to dataset\n",
      "data32.fits added to dataset\n",
      "data113.fits added to dataset\n",
      "data22.fits added to dataset\n",
      "data168.fits added to dataset\n",
      "data128.fits added to dataset\n",
      "data48.fits added to dataset\n",
      "data101.fits added to dataset\n",
      "data0.fits added to dataset\n",
      "data248.fits added to dataset\n",
      "data60.fits added to dataset\n",
      "data234.fits added to dataset\n",
      "data87.fits added to dataset\n",
      "data166.fits added to dataset\n",
      "data81.fits added to dataset\n",
      "data247.fits added to dataset\n",
      "data140.fits added to dataset\n",
      "data172.fits added to dataset\n",
      "data241.fits added to dataset\n",
      "data2.fits added to dataset\n",
      "data237.fits added to dataset\n",
      "data95.fits added to dataset\n",
      "data44.fits added to dataset\n",
      "data64.fits added to dataset\n",
      "data191.fits added to dataset\n",
      "data194.fits added to dataset\n",
      "data74.fits added to dataset\n",
      "data9.fits added to dataset\n",
      "data119.fits added to dataset\n",
      "data216.fits added to dataset\n",
      "data69.fits added to dataset\n",
      "data181.fits added to dataset\n",
      "data156.fits added to dataset\n",
      "data243.fits added to dataset\n",
      "data220.fits added to dataset\n",
      "data150.fits added to dataset\n",
      "data110.fits added to dataset\n",
      "data77.fits added to dataset\n",
      "data207.fits added to dataset\n",
      "data155.fits added to dataset\n",
      "data4.fits added to dataset\n",
      "data78.fits added to dataset\n",
      "data147.fits added to dataset\n",
      "data235.fits added to dataset\n",
      "data163.fits added to dataset\n",
      "data29.fits added to dataset\n",
      "data242.fits added to dataset\n",
      "data167.fits added to dataset\n",
      "data50.fits added to dataset\n",
      "data94.fits added to dataset\n",
      "data62.fits added to dataset\n",
      "data152.fits added to dataset\n",
      "data122.fits added to dataset\n",
      "data39.fits added to dataset\n",
      "data195.fits added to dataset\n",
      "data53.fits added to dataset\n",
      "data192.fits added to dataset\n",
      "data72.fits added to dataset\n",
      "data73.fits added to dataset\n",
      "data233.fits added to dataset\n",
      "data177.fits added to dataset\n",
      "data127.fits added to dataset\n",
      "data54.fits added to dataset\n",
      "data169.fits added to dataset\n",
      "data153.fits added to dataset\n",
      "data196.fits added to dataset\n",
      "data80.fits added to dataset\n",
      "data139.fits added to dataset\n",
      "data85.fits added to dataset\n",
      "data221.fits added to dataset\n",
      "data225.fits added to dataset\n",
      "data55.fits added to dataset\n",
      "data75.fits added to dataset\n",
      "data86.fits added to dataset\n"
     ]
    }
   ],
   "source": [
    "# Create images and masks arrays lists\n",
    "images = []\n",
    "masks = []\n",
    "\n",
    "# Create df to store the star data inside each fits file\n",
    "star_data = []\n",
    "\n",
    "# Create a list of all the fits files in the dataset folder\n",
    "fits_files = os.listdir('data/fits/')\n",
    "\n",
    "# For all the fits files in the dataset folder specified in file_path, extract the image and mask arrays to the respective lists\n",
    "file_path = 'data/fits/'\n",
    "# for file in os.listdir(file_path):\n",
    "for file in os.listdir(file_path):\n",
    "    if file.endswith('.png'):\n",
    "        os.remove(file_path + file)\n",
    "    if file.startswith('data') and file.endswith('.fits'):\n",
    "        images.append(extractImageArray(file_path + file))\n",
    "        masks.append(extractPixelMaskArray(file_path + file))\n",
    "        star_data.append(extract_star_catalog(file_path + file))\n",
    "\n",
    "        print(file + ' added to dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803fd51f",
   "metadata": {},
   "source": [
    "# Prepare the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650532b",
   "metadata": {},
   "source": [
    "### Convert to 3-Channel Images\n",
    "\n",
    "The images we have are 512 x 512 pixels, but our model requires them to be in the shape `(512, 512, 3)`, similar to standard RGB images. To achieve this, we stack the single-channel images along the last axis three times, converting them into 3-channel images. This transformation is necessary because the model typically expects 3-channel input images.\n",
    "\n",
    "For the masks, the model expects them to be in the shape `(512, 512, 1)`. Therefore, we expand the masks along the last axis to add a new dimension, ensuring they have the correct shape.\n",
    "\n",
    "Additionally, both the images and masks need to be converted to NumPy arrays, as this is the desired format for the training model. Below, we perform these conversions to ensure the data is in the correct format for training.\n",
    "\n",
    "Notice when displaying the shape of the `train_images` list below we see it is an array of 250 images of the shape mentioned above, giving us a shape `(250, 512, 512, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eee6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_images = stackImages(images)\n",
    "stacked_masks = stackMasks(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801c4f0",
   "metadata": {},
   "source": [
    "### Normalize the Images\n",
    "\n",
    "To standardize the pixel values in our images, we need to normalize them to a common range.\n",
    "We will use min-max normalization to scale the pixel values to a range between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce79b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_images = normalizeImages(stacked_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f855b",
   "metadata": {},
   "source": [
    "###  Prepare the model for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8beae7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "\n",
    "# Define the base exponent - Change this number to increase or decrease the number of filters by a power of 2\n",
    "base_exponent = 5\n",
    "#############################################\n",
    "# base_exponent = 5, so filters result in [32, 64, 128, 256, 512], this was the original value\n",
    "# base_exponent = 6, so filters result in [64, 128, 256, 512, 1024]\n",
    "# base_exponent = 7, so filters result in [128, 256, 512, 1024, 2048]\n",
    "# base_exponent = 8, so filters result in [256, 512, 1024, 2048, 4096]\n",
    "# base_exponent = 9, so filters result in [512, 1024, 2048, 4096, 8192]\n",
    "# base_exponent = 10, so filters result in [1024, 2048, 4096, 8192, 16384]\n",
    "\n",
    "# Generate the filters based on powers of 2\n",
    "filters = [2 ** (base_exponent + i) for i in range(5)]\n",
    "#############################################\n",
    "# This list comprehension generates the filter sizes by raising 2 to the powers starting from the base exponent and increasing by 1 for each subsequent filter.\n",
    "#############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d102d6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 64, 128, 256, 512]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c06f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparameters = {\n",
    "    'input_shape': (512, 512, 3),\n",
    "    'filters': filters,\n",
    "    'kernel_size': (3, 3),\n",
    "    'activation': 'relu',\n",
    "    'padding': 'same',\n",
    "    # 'initializer': he_uniform(),\n",
    "    'initializer': he_uniform,\n",
    "    # 'optimizer': 'adam',\n",
    "    'optimizer': Adam(learning_rate=0.00005),\n",
    "    # 'loss': weightedBinaryCrossEntropy,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'weights' : {0 : 1.0, 1 : 5.0},\n",
    "    'metrics': ['accuracy'],\n",
    "    'epochs': 100,\n",
    "    'batch_size': 4,\n",
    "    'early_stopping_patience': 10,\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 0,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Create and compile the model using hyperparameters\n",
    "model = unet_model(\n",
    "    input_shape=hyperparameters['input_shape'],\n",
    "    filters=hyperparameters['filters'],\n",
    "    kernel_size=hyperparameters['kernel_size'],\n",
    "    activation=hyperparameters['activation'],\n",
    "    padding=hyperparameters['padding'],\n",
    "    initializer=hyperparameters['initializer']\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=hyperparameters['optimizer'],\n",
    "    loss=hyperparameters['loss'],\n",
    "    metrics=hyperparameters['metrics']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8932a853",
   "metadata": {},
   "source": [
    "**Create Generators for Training and Validation**:\n",
    "   - Use the `flow` method to create generators for training and validation images and masks.\n",
    "   - Ensure that the `seed` parameter is the same for both image and mask generators to maintain alignment.\n",
    "\n",
    " **Custom Generator**:\n",
    "   - Define a custom generator function `custom_generator` that yields a tuple (images, masks, sample_weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af76ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(stacked_images, stacked_masks, test_size=hyperparameters['test_size'], random_state=hyperparameters['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "798ff170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:  (200, 512, 512, 3)\n",
      "Training masks:  (200, 512, 512, 1)\n",
      "Validation images:  (50, 512, 512, 3)\n",
      "Validation masks:  (50, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "# Show distribution of training and validation sets\n",
    "print('Training images: ', train_images.shape)\n",
    "print('Training masks: ', train_masks.shape)\n",
    "print('Validation images: ', val_images.shape)\n",
    "print('Validation masks: ', val_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f8de9",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851767c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 00:56:26.342012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-11-18 00:56:28.378463: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5edec3980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-18 00:56:28.378504: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2024-11-18 00:56:28.401019: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-18 00:56:28.638650: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 21s 123ms/step - loss: 66.2607 - accuracy: 0.9618 - val_loss: 12.2195 - val_accuracy: 0.9794\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 7s 147ms/step - loss: 31.6754 - accuracy: 0.9687 - val_loss: 7.7368 - val_accuracy: 0.9792\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 7s 138ms/step - loss: 25.1597 - accuracy: 0.9671 - val_loss: 6.8003 - val_accuracy: 0.9726\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 7s 141ms/step - loss: 21.1410 - accuracy: 0.9683 - val_loss: 6.5929 - val_accuracy: 0.9673\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 7s 145ms/step - loss: 18.8424 - accuracy: 0.9665 - val_loss: 6.7979 - val_accuracy: 0.9555\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 17.0350 - accuracy: 0.9673 - val_loss: 4.7386 - val_accuracy: 0.9743\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 7s 141ms/step - loss: 15.4267 - accuracy: 0.9664 - val_loss: 3.8722 - val_accuracy: 0.9839\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 7s 147ms/step - loss: 14.2333 - accuracy: 0.9669 - val_loss: 5.7201 - val_accuracy: 0.9524\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 7s 134ms/step - loss: 13.2694 - accuracy: 0.9673 - val_loss: 6.2894 - val_accuracy: 0.9361\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 12.6755 - accuracy: 0.9670 - val_loss: 3.1540 - val_accuracy: 0.9852\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 8s 151ms/step - loss: 12.0742 - accuracy: 0.9670 - val_loss: 6.2073 - val_accuracy: 0.9293\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 7s 138ms/step - loss: 11.2705 - accuracy: 0.9670 - val_loss: 7.3214 - val_accuracy: 0.9077\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 7s 147ms/step - loss: 10.7696 - accuracy: 0.9659 - val_loss: 3.0596 - val_accuracy: 0.9764\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 7s 146ms/step - loss: 10.6317 - accuracy: 0.9668 - val_loss: 5.7732 - val_accuracy: 0.9269\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 5s 99ms/step - loss: 9.9957 - accuracy: 0.9673 - val_loss: 6.3031 - val_accuracy: 0.9078\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 7s 148ms/step - loss: 9.5874 - accuracy: 0.9654 - val_loss: 2.6807 - val_accuracy: 0.9769\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 9s 170ms/step - loss: 9.1461 - accuracy: 0.9660 - val_loss: 2.6251 - val_accuracy: 0.9770\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 7s 148ms/step - loss: 8.7767 - accuracy: 0.9670 - val_loss: 2.7624 - val_accuracy: 0.9690\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 8.3198 - accuracy: 0.9690 - val_loss: 5.8099 - val_accuracy: 0.8996\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 7s 142ms/step - loss: 8.6681 - accuracy: 0.9664 - val_loss: 2.5353 - val_accuracy: 0.9689\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 8s 151ms/step - loss: 7.7853 - accuracy: 0.9685 - val_loss: 2.6078 - val_accuracy: 0.9665\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 7s 143ms/step - loss: 7.6014 - accuracy: 0.9653 - val_loss: 2.3584 - val_accuracy: 0.9699\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 7.3404 - accuracy: 0.9673 - val_loss: 2.1025 - val_accuracy: 0.9779\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 7s 137ms/step - loss: 7.0002 - accuracy: 0.9667 - val_loss: 3.1683 - val_accuracy: 0.9464\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 7s 141ms/step - loss: 6.9899 - accuracy: 0.9670 - val_loss: 2.0444 - val_accuracy: 0.9743\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 7s 141ms/step - loss: 6.9295 - accuracy: 0.9656 - val_loss: 1.7688 - val_accuracy: 0.9837\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 7s 138ms/step - loss: 6.6346 - accuracy: 0.9670 - val_loss: 2.2534 - val_accuracy: 0.9672\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 6.2999 - accuracy: 0.9672 - val_loss: 1.8735 - val_accuracy: 0.9763\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 7s 142ms/step - loss: 6.1112 - accuracy: 0.9654 - val_loss: 1.5322 - val_accuracy: 0.9891\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 7s 139ms/step - loss: 6.2262 - accuracy: 0.9667 - val_loss: 1.6662 - val_accuracy: 0.9803\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 7s 140ms/step - loss: 5.7863 - accuracy: 0.9676 - val_loss: 3.0167 - val_accuracy: 0.9358\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 7s 142ms/step - loss: 5.7698 - accuracy: 0.9663 - val_loss: 1.7467 - val_accuracy: 0.9750\n",
      "Epoch 33/100\n",
      " 8/50 [===>..........................] - ETA: 5s - loss: 5.6482 - accuracy: 0.9631"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Implement Early stopping to cut useless epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # or another metric like 'val_accuracy'\n",
    "    patience=hyperparameters['early_stopping_patience'],         # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restores the model to the best state after stopping\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images, train_masks, \n",
    "    validation_data=(val_images, val_masks), \n",
    "    epochs=hyperparameters['epochs'], \n",
    "    batch_size=hyperparameters['batch_size'],\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=hyperparameters['weights']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "user = getpass.getuser()\n",
    "\n",
    "# Save the model\n",
    "saved_models_path = 'models/saved_models/'\n",
    "training_size = str(len(train_images))\n",
    "saved_model_name = datetime.datetime.now().strftime(\"%Y_%m_%d-%H%M_\") + training_size + '_unet_model_' + user +  '.keras'\n",
    "model.save(saved_models_path + saved_model_name)\n",
    "\n",
    "#log model parameters, time, and user\n",
    "write_to_log(history, hyperparameters, saved_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9056adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training loss and validation loss\n",
    "print('Training loss: ', history.history['loss'][-1])\n",
    "print('Validation loss: ', history.history['val_loss'][-1])\n",
    "\n",
    "# Show training accuracy and validation accuracy\n",
    "print('Training accuracy: ', history.history['accuracy'][-1])\n",
    "print('Validation accuracy: ', history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(24, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('results/figures/' + saved_model_name.removesuffix('unet_model.keras') + '_training_validation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ff4ef-a8b3-4b9f-af7b-cdf0c5437e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a larger figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], color='blue', linestyle='-', linewidth=2, label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', linestyle='--', linewidth=2, label='Validation Loss')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Validation Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "# Add a grid for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Add legend to differentiate between training and validation loss\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "\n",
    "# Set limits for better visualization\n",
    "plt.xlim(0, len(history.history['loss']) - 1)  # From epoch 0 to the last epoch\n",
    "plt.ylim(min(history.history['loss']) * 0.95, max(history.history['val_loss']) * 1.05)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "# plt.savefig('results/figures/' + saved_model_name.removesuffix('unet_model.keras') + '_training_validation_loss.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
